# Respons√°vel por: l√≥gica comum de extra√ß√£o, retry, pagina√ß√£o, compara√ß√£o JSON

import requests
import time
from datetime import datetime
from sqlalchemy.dialects.postgresql import insert
from config.settings import headers
from config.database import Session

# =======================================================
# 1. FUN√á√ÉO DE COMPARA√á√ÉO DE JSON 
# =======================================================

def comparar_jsons(json1, json2):
    """
    Compara dois JSONs de forma inteligente
    Retorna True se s√£o diferentes, False se s√£o iguais
    """
    try:
        # Converter ambos para string normalizada para compara√ß√£o
        # Isso garante que diferen√ßas na ordem dos campos sejam ignoradas
        if isinstance(json1, dict) and isinstance(json2, dict):
            # Ordenar as chaves recursivamente para compara√ß√£o consistente
            def ordenar_dict(obj):
                if isinstance(obj, dict):
                    return {k: ordenar_dict(v) for k, v in sorted(obj.items())} # Sorted √© para ordenar as chaves do dicion√°rio
                elif isinstance(obj, list):
                    return [ordenar_dict(item) for item in obj]
                return obj
            
            json1_ordenado = ordenar_dict(json1)
            json2_ordenado = ordenar_dict(json2)
            
            return json1_ordenado != json2_ordenado
        else:
            return json1 != json2
    except Exception as e:
        print(f"Erro ao comparar JSONs: {e}")
        # Em caso de erro, assume que s√£o diferentes para atualizar
        return True

# =======================================================
# 2. CLASSE BASE PARA EXTRATORES
# =======================================================

class BaseExtractor:
    """
    Classe base que cont√©m toda a l√≥gica comum de extra√ß√£o
    Outros extractors v√£o herdar desta classe e s√≥ mudar o que √© espec√≠fico
    """
    
    def __init__(self, base_url, model_class): # Self √© para acessar as vari√°veis da classe
        """
        Inicializa o extractor base
        Args:
            base_url: URL da API para este endpoint
            model_class: Classe do modelo SQLAlchemy (ex: ContatoRaw)
        """
        self.base_url = base_url 
        self.headers = headers
        self.model_class = model_class

# =======================================================
# 3. FUN√á√ÉO DE EXTRA√á√ÉO DOS DADOS (COM RETRY E PARADA)
# =======================================================  

    # Definindo a fun√ß√£o de extra√ß√£o e fazendo a requisi√ß√£o
    def extract_dados_bling_paginado(self, limite_por_pagina=100, delay_entre_requests=0.35, max_paginas=1000, max_tentativas=3): # Extrai todos os registros da API Bling usando pagina√ß√£o
        """
        Extrai todos os dados de qualquer endpoint da API Bling usando pagina√ß√£o
        PARA COMPLETAMENTE se n√£o conseguir obter uma p√°gina ap√≥s 3 tentativas
        
        Args   
            limite_por_pagina (int): N√∫mero m√°ximo de registros por p√°gina (m√°x 100)
            delay_entre_requests (float): Tempo de espera entre requests em segundos
            max_paginas (int): Limite m√°ximo de p√°ginas para evitar loops infinitos
            max_tentativas (int): N√∫mero de tentativas por p√°gina antes de parar tudo

        Returns:
            list: Lista com todos os dados de cada endpoint extra√≠dos
        """
        todos_registros = []      # Lista gen√©rica para armazenar todos os registros
        pagina_atual = 1          # Come√ßamos da p√°gina 1
        total_paginas = None      # Vamos descobrir isso na primeira requisi√ß√£o
        registros_unicos = set()   # Para evitar duplicatas
        
        print(f"Iniciando extra√ß√£o paginada...")
        print(f"Configura√ß√µes: delay={delay_entre_requests}s, max_tentativas={max_tentativas}")

        while pagina_atual <= max_paginas: # Prote√ß√£o contra loop infinito
            # Par√¢metros para requisi√ß√£o
            params = {
                "limite": limite_por_pagina,
                "pagina": pagina_atual
            }

            print(f"Processando p√°gina {pagina_atual}{'/' + str(total_paginas) if total_paginas else ''}...")
        
            # Sistema de retry para cada p√°gina
            sucesso = False
            for tentativa in range(max_tentativas):
                try:
                    # Fazendo requisi√ß√£o para a API com timeout
                    response = requests.get(
                        self.base_url,
                        headers=self.headers,
                        params=params,
                        timeout=30  # Timeout de 30 segundos
                    )
                    
                    # Verificando se a requisi√ß√£o foi bem sucedida
                    if response.status_code != 200:
                        print(f"Erro HTTP {response.status_code} na p√°gina {pagina_atual} (tentativa {tentativa + 1}/{max_tentativas})")
                        print(f"Resposta: {response.text}")
                        
                        if tentativa < max_tentativas - 1:
                            delay_erro = delay_entre_requests * 2
                            print(f"Aguardando {delay_erro}s antes de tentar novamente...")
                            time.sleep(delay_erro)
                            continue
                        else:
                            print(f"ERRO CR√çTICO: Falha HTTP ap√≥s {max_tentativas} tentativas na p√°gina {pagina_atual}")
                            print("INTERROMPENDO EXTRA√á√ÉO para evitar perda de dados")
                            raise Exception(f"Falha HTTP {response.status_code} ap√≥s {max_tentativas} tentativas")

                    # Convertendo a resposta para JSON
                    dados = response.json()
                    sucesso = True
                    break

                except (requests.exceptions.ConnectionError, 
                        requests.exceptions.Timeout,
                        requests.exceptions.RequestException) as e:
                    
                    print(f"Erro de conex√£o na p√°gina {pagina_atual} (tentativa {tentativa + 1}/{max_tentativas}): {e}")
                    
                    if tentativa < max_tentativas - 1:
                        # Delay progressivo: 0.35s ‚Üí 0.7s ‚Üí 1.4s
                        delay_progressivo = delay_entre_requests * (2 ** tentativa)
                        print(f"Aguardando {delay_progressivo:.1f}s antes de tentar novamente...")
                        time.sleep(delay_progressivo)
                    else:
                        print(f"ERRO CR√çTICO: Falha de conex√£o ap√≥s {max_tentativas} tentativas na p√°gina {pagina_atual}")
                        print("INTERROMPENDO EXTRA√á√ÉO para evitar perda de dados")
                        print("Verifique sua conex√£o de internet e tente novamente")
                        raise Exception(f"Falha de conex√£o ap√≥s {max_tentativas} tentativas: {e}")
                except Exception as e:
                    print(f"Erro inesperado na p√°gina {pagina_atual} (tentativa {tentativa + 1}/{max_tentativas}): {e}")
                    
                    if tentativa < max_tentativas - 1:
                        time.sleep(delay_entre_requests)
                    else:
                        print(f"ERRO CR√çTICO: Erro n√£o recuper√°vel na p√°gina {pagina_atual}")
                        print("INTERROMPENDO EXTRA√á√ÉO para an√°lise do erro")
                        raise Exception(f"Erro n√£o recuper√°vel ap√≥s {max_tentativas} tentativas: {e}")
            
            # Se chegou aqui, obteve sucesso na requisi√ß√£o
            if not sucesso:
                # Esta condi√ß√£o n√£o deveria ser alcan√ßada devido aos raises acima
                print(f"ERRO INTERNO: L√≥gica de retry falhou")
                raise Exception("Falha interna no sistema de retry")
                
            # Debug: mostrar estrutura da resposta na primeira p√°gina
            if pagina_atual == 1:
                print(f"Total informado pela API: {dados.get('total', 'N/A')}")
                print(f"Total de p√°ginas informado: {dados.get('total_pages', 'N/A')}")

            # Na primeira requisi√ß√£o, capturamos o total de p√°ginas
            if total_paginas is None:
                total_paginas = dados.get("total_pages", 1)
                total_registros = dados.get("total", 0)
                print(f"Total de p√°ginas: {total_paginas}")
                print(f"Total de registros: {total_registros}")

            # Extraindo os registros da p√°gina atual
            registros_pagina = dados.get("data", [])
            
            # Se n√£o h√° mais registros, paramos o loop
            if not registros_pagina:
                print(f"P√°gina {pagina_atual} vazia. Finalizando extra√ß√£o.")
                break

            # Verificar se temos registro novos ou se estamos vendo repetidos
            registros_novos = 0
            for registro in registros_pagina:
                if registro['id'] not in registros_unicos:
                    registros_unicos.add(registro['id'])
                    todos_registros.append(registro)
                    registros_novos += 1

            print(f"Extra√≠dos {len(registros_pagina)} registro da p√°gina {pagina_atual} ({registros_novos} novos)")
            
            # Se n√£o encontramos registro novos, provavelmente chegamos ao fim
            if registros_novos == 0:
                print(f"Nenhum registro novo na p√°gina {pagina_atual}. Finalizando.")
                break
            
            # Se chegamos na √∫ltima p√°gina OFICIAL, mas ainda h√° dados, continuamos
            if pagina_atual >= total_paginas and len(registros_pagina) < limite_por_pagina:
                print(f"√öltima p√°gina oficial ({total_paginas}) processada e com menos que {limite_por_pagina} registros. Finalizando.")
                break

            # Incrementamos para a pr√≥xima p√°gina
            pagina_atual += 1
            
            # Pausa entre requests para n√£o sobrecarregar a API
            if delay_entre_requests > 0:
                time.sleep(delay_entre_requests)
        
        print(f"Extra√ß√£o finalizada com sucesso. Total de registro coletados: {len(todos_registros)}")
        print(f"P√°ginas processadas: {pagina_atual - 1}")
        return todos_registros   

# =============================================================
# 4. FUN√á√ÉO PARA SALVAR NO POSTGRES (COMPARAR ANTES DE SALVAR)
# =============================================================

    def salvar_dados_postgres_bulk(self, lista_dados): # Salva m√∫ltiplos registros no Postgres de forma eficiente usando bulk insert
        """
        Salva dados usando compara√ß√£o inteligente:
        - Novos registros: INSERT
        - Registros existentes id√™nticos: SKIP
        - Registros existentes diferentes: UPDATE
        """
        if not lista_dados:
            print("Nenhum dado para salvar.")
            return {"inseridos": 0, "atualizados": 0, "ignorados": 0, "total": 0}
        
        session = Session()
        stats = {"inseridos": 0, "atualizados": 0, "ignorados": 0, "total": len(lista_dados)}

        try:
            print(f"üîç Buscando registros existentes para compara√ß√£o...")
            inicio_busca = datetime.now()

            # Buscar TODOS os registros existentes com seus JSONs
            # Isso √© mais eficiente que buscar um por um
            registros_existentes = {}
            existing_records = session.query(
                self.model_class.bling_id,
                self.model_class.dados_json
            ).all()

            # Carregando os registros existentes
            for record in existing_records:
                registros_existentes[record.bling_id] = record.dados_json
            
            fim_busca = datetime.now()
            print(f"üìã {len(registros_existentes)} registros existentes carregados em {fim_busca - inicio_busca}")

            # Classificar os dados em: novos, diferentes, id√™nticos
            registros_novos = []
            registros_para_atualizar = []
            
            print(f"üîç Comparando {len(lista_dados)} registros...")
            inicio_comparacao = datetime.now()
            
            for i, dados in enumerate(lista_dados): # Enumerates ajuda com loops que exigem um contador, adicionando um √≠ndice a cada item em um iter√°vel
                bling_id = dados['bling_id']
                novo_json = dados['dados_json']
                
                # Mostrar progresso a cada 1000 registros
                if (i + 1) % 1000 == 0:
                    print(f"Processados {i + 1}/{len(lista_dados)} registros...")
                
                if bling_id not in registros_existentes:
                    # Registro novo ‚Üí INSERT
                    registros_novos.append({
                        'bling_id': bling_id,
                        'dados_json': novo_json,
                        'data_ingestao': datetime.now(),
                        'status_processamento': 'pendente'
                    })
                    stats["inseridos"] += 1
                    
                else:
                    # Registro existe ‚Üí comparar conte√∫do
                    json_existente = registros_existentes[bling_id]
                    
                    if comparar_jsons(json_existente, novo_json):
                        # Conte√∫do diferente ‚Üí UPDATE
                        registros_para_atualizar.append(dados)
                        stats["atualizados"] += 1
                    else:
                        # Conte√∫do id√™ntico ‚Üí SKIP
                        stats["ignorados"] += 1
            
            fim_comparacao = datetime.now()
            print(f"‚úÖ Compara√ß√£o conclu√≠da em {fim_comparacao - inicio_comparacao}")
            
            # Relat√≥rio da classifica√ß√£o
            print(f"\nüìä CLASSIFICA√á√ÉO DOS REGISTROS:")
            print(f"   ‚Ä¢ üÜï Novos (inserir): {stats['inseridos']}")
            print(f"   ‚Ä¢ üîÑ Diferentes (atualizar): {stats['atualizados']}")
            print(f"   ‚Ä¢ ‚è≠Ô∏è Id√™nticos (ignorar): {stats['ignorados']}")
            
            # BULK INSERT dos registros novos (mais r√°pido)
            if registros_novos:
                print(f"\nüíæ Inserindo {len(registros_novos)} registros novos...")
                inicio_insert = datetime.now()
                session.bulk_insert_mappings(self.model_class, registros_novos)
                fim_insert = datetime.now()
                print(f"‚úÖ Inser√ß√µes conclu√≠das em {fim_insert - inicio_insert}")

            # UPDATE dos registros diferentes (um por um, mas s√≥ os necess√°rios)
            if registros_para_atualizar:
                print(f"\nüîÑ Atualizando {len(registros_para_atualizar)} registros diferentes...")
                inicio_update = datetime.now()
                
                for i, dados in enumerate(registros_para_atualizar):
                    if (i + 1) % 100 == 0:
                        print(f"Atualizados {i + 1}/{len(registros_para_atualizar)} registros...")
                    
                    stmt = insert(self.model_class).values( # stmt = statement 
                        bling_id=dados['bling_id'],
                        dados_json=dados['dados_json'],
                        data_ingestao=datetime.now(),
                        status_processamento='pendente'
                    )
                    
                    stmt = stmt.on_conflict_do_update( # On conflict do update √© para atualizar o registro se j√° existir
                        index_elements=['bling_id'],
                        set_={
                            'dados_json': stmt.excluded.dados_json, 
                            'data_ingestao': stmt.excluded.data_ingestao,
                            'status_processamento': 'pendente'
                        }
                    )
                    
                    session.execute(stmt)
                
                fim_update = datetime.now()
                print(f"‚úÖ Atualiza√ß√µes conclu√≠das em {fim_update - inicio_update}")

            # Se n√£o h√° nada para fazer, s√≥ reportar
            if not registros_novos and not registros_para_atualizar:
                print(f"\n‚ú® Nenhum registro novo ou alterado! Banco j√° est√° atualizado.")

            session.commit()

            # Relat√≥rio final detalhado
            print(f"\nüéâ SALVAMENTO CONCLU√çDO!")
            print(f"üìä Estat√≠sticas detalhadas:")
            print(f"   ‚Ä¢ üÜï Registros inseridos: {stats['inseridos']}")
            print(f"   ‚Ä¢ üîÑ Registros atualizados: {stats['atualizados']}")
            print(f"   ‚Ä¢ ‚è≠Ô∏è Registros ignorados (id√™nticos): {stats['ignorados']}")
            print(f"   ‚Ä¢ üìà Total processado: {stats['total']}")
            print(f"   ‚Ä¢ üíæ Opera√ß√µes de escrita: {stats['inseridos'] + stats['atualizados']}")
            print(f"   ‚Ä¢ ‚ö°  Economia: {stats['ignorados']} escritas desnecess√°rias evitadas!")
            
            return stats
            
        except Exception as e:
            session.rollback() # Rollback √© para desfazer as opera√ß√µes se ocorrer um erro
            print(f"‚ùå Erro ao salvar dados: {e}")
            raise
        finally:
            session.close()  # Sempre fechar a sess√£o do banco de dados